{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wgBNBLxzDlLq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,SimpleRNN,Dense"
      ],
      "metadata": {
        "id": "fIUSBCwjGIyY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plays=pd.read_csv(\"/content/Shakespeare_data.csv\")\n",
        "plays.shape\n",
        "plays.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0vPl40DIBFx",
        "outputId": "4a761e93-b89d-4417-ed62-6e5ca825865c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Dataline', 'Play', 'PlayerLinenumber', 'ActSceneLine', 'Player',\n",
              "       'PlayerLine'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_lines=plays['PlayerLine'].sample(n=10000,random_state=42)\n",
        "data=\" \".join(samples_lines)"
      ],
      "metadata": {
        "id": "4KzXCuFqIWJs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcS7RtVdZiDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "mWPotfP3KGQ6",
        "outputId": "bcb8f5e8-6cc5-434a-f406-c5515ab9fb74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That hath deprived me of your grace and favour, Their bodies, even to loathing, for they so stunk, Men at some time are masters of their fates: Disgorges such a tempest forth, That monster, custom, who all sense doth eat, To this chair bind him. Villain, thou shalt find-- Dexterity so obeying appetite Hector, in view of Trojans and of Greeks, Who know the world, see heaven, but, feeling woe, I should my tears let fall upon your cheek, Let not that doctor e'er come near my house: Arise, and say how thou camest here. Have I not heard these islanders shout out and one thing more, that you be never so hardy to And say I am Revenge, sent from below To furnish me upon my longing journey. All his revenue. And thus the native hue of resolution Why, art thou mad, old fellow? porringer fell off her head, for kindling such a That you shall stifle in your own report Is not this suit of mine, that thou declare It is as easy to count atomies as to resolve the But let this same be presently perform'd, The offers we have sent you. Now to deliver her possession up O Jupiter! there's no comparison. That none shall have access unto Bianca Have done me shame: brave soldier, pardon me, Dearer than eye-sight, space, and liberty, Nay, but it is not so. Be not you spoke with, but by mighty suit: Help, help, ho! Go to, sir: tell me, do you know Madam Silvia? That is thy means to live. Do thou but think To Mantua, where I hear he makes abode, Thunder. Third Apparition: a Child crowned, with a tree in his hand What folly 'tis to hazard life for ill! By heaven, it shall not go! And wilt thou have me? Of space had pointed him sharp as my needle, That I did never, no, nor never can, They bore him barefaced on the bier, And be it moon, or sun, or what you please: Should he sit here? This act persuades me Ay, he does well enough if he be disposed, and so do And calls them brothers, friends and countrymen. And I will. Hear me, my liege: For I am arm'd so strong in honesty No, if I digg'd up thy forefathers' graves Touch not the boy, he is of royal blood. I am so far already in your gifts,-- I would thou grew'st unto the shores o' the haven, From forth the fatal loins of these two foes Be these the wretches that we play'd at dice for? He hath refused it in the open court: To seek out sorrow that dwells every where. perfect gallows. Stand fast, good Fate, to his That's it, I would have said the very same. Exit what we may be. God be at your table! The Lady Anne pass from her coronation? Strike a free march to Troy! with comfort go: hang'd first. A fair one are you--well you fit our ages Ay. The very doors and windows savour vilely. I will not harbour in this town to-night: By my fidelity, this is not well, Master Ford, this There, my lord: Whereat, with blade, with bloody blameful blade, Claribel. but blow them to their trial, the bubbles are out. What say ye, countrymen? will ye relent, As thou dost swallow up this good king's blood I will say nothing. death: her death itself, which could not be her That you might see your shadow. I have heard, To set thee here? Come our lovely lady nigh, And that you fly them as you swear them lordship, And buy men's voices to commend our deeds: On which I'll toss the flower-de-luce of France. Your grace, that fed my country with your corn, Writes that knows me to be in love, yet I am in love, but a Well, come, my Kate, we will unto your father's Rankly abused: but know, thou noble youth, All points of my command. Brentford: but that my admirable dexterity of wit, bass-viol, in a case of leather, the man, sir, How to lament the cause. I'll beg one boon, Four legs and two voices: a most delicate monster! could not have owed her a more rooted love. Proceed. SCENE VI. The same. A banqueting-room in Timon's house. Will kneel to him with thanks. And a demand who is't shall die, I'd say Oft have I heard of sanctuary men,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "word_index=tokenizer.word_index\n",
        "total_words=len(word_index)+1"
      ],
      "metadata": {
        "id": "vCnzvyDsJDDK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "token_list=tokenizer.texts_to_sequences([data])[0]\n",
        "for i in range(1,len(token_list) ):\n",
        "  n_gram_sequence=token_list[:i+1]\n",
        "  input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "NMk_qUhjL8F2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len=max([len(seq) for seq in input_sequences])\n",
        "input_sequences=pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre')"
      ],
      "metadata": {
        "id": "eK9HGgqsRTm7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y=to_categorical(y,num_classes=total_words)"
      ],
      "metadata": {
        "id": "eMFu1KTeS5Aw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(total_words,1000,input_length=max_sequence_len-1))\n",
        "model.add(SimpleRNN(200))\n",
        "model.add(Dense(total_words,activation='softmax'))"
      ],
      "metadata": {
        "id": "mZkNCvTbTpBA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOky7Dw9Ty36",
        "outputId": "bdaf2324-974e-4b45-bba9-c90dcb538cd7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 751, 100)          38700     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 150)               37650     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 387)               58437     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134787 (526.51 KB)\n",
            "Trainable params: 134787 (526.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is8aPI0uT6rc",
        "outputId": "27caa202-e8dd-4aff-d540-5f5ac0332b84"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "24/24 [==============================] - 23s 870ms/step - loss: 5.9683 - accuracy: 0.0027\n",
            "Epoch 2/26\n",
            "24/24 [==============================] - 16s 685ms/step - loss: 5.9646 - accuracy: 0.0040\n",
            "Epoch 3/26\n",
            "24/24 [==============================] - 16s 661ms/step - loss: 5.9832 - accuracy: 0.0107\n",
            "Epoch 4/26\n",
            "24/24 [==============================] - 16s 680ms/step - loss: 6.0172 - accuracy: 0.0226\n",
            "Epoch 5/26\n",
            "24/24 [==============================] - 16s 638ms/step - loss: 5.9714 - accuracy: 0.0080\n",
            "Epoch 6/26\n",
            "24/24 [==============================] - 16s 652ms/step - loss: 5.9526 - accuracy: 0.0146\n",
            "Epoch 7/26\n",
            "24/24 [==============================] - 16s 661ms/step - loss: 6.0554 - accuracy: 0.0133\n",
            "Epoch 8/26\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 6.0336 - accuracy: 0.0120\n",
            "Epoch 9/26\n",
            "24/24 [==============================] - 17s 719ms/step - loss: 6.0150 - accuracy: 0.0053\n",
            "Epoch 10/26\n",
            "24/24 [==============================] - 15s 639ms/step - loss: 5.9660 - accuracy: 0.0133\n",
            "Epoch 11/26\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 5.9119 - accuracy: 0.0160\n",
            "Epoch 12/26\n",
            "24/24 [==============================] - 15s 643ms/step - loss: 5.9144 - accuracy: 0.0120\n",
            "Epoch 13/26\n",
            "24/24 [==============================] - 15s 642ms/step - loss: 5.9600 - accuracy: 0.0107\n",
            "Epoch 14/26\n",
            "24/24 [==============================] - 17s 720ms/step - loss: 5.9597 - accuracy: 0.0080\n",
            "Epoch 15/26\n",
            "24/24 [==============================] - 15s 645ms/step - loss: 5.8267 - accuracy: 0.0133\n",
            "Epoch 16/26\n",
            "24/24 [==============================] - 15s 638ms/step - loss: 5.9155 - accuracy: 0.0093\n",
            "Epoch 17/26\n",
            "24/24 [==============================] - 15s 640ms/step - loss: 5.8822 - accuracy: 0.0240\n",
            "Epoch 18/26\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 5.9497 - accuracy: 0.0173\n",
            "Epoch 19/26\n",
            "24/24 [==============================] - 17s 714ms/step - loss: 5.8852 - accuracy: 0.0146\n",
            "Epoch 20/26\n",
            "24/24 [==============================] - 15s 638ms/step - loss: 5.8078 - accuracy: 0.0213\n",
            "Epoch 21/26\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 5.7776 - accuracy: 0.0266\n",
            "Epoch 22/26\n",
            "24/24 [==============================] - 15s 643ms/step - loss: 5.8724 - accuracy: 0.0146\n",
            "Epoch 23/26\n",
            "24/24 [==============================] - 15s 640ms/step - loss: 5.8221 - accuracy: 0.0120\n",
            "Epoch 24/26\n",
            "24/24 [==============================] - 16s 691ms/step - loss: 5.8045 - accuracy: 0.0240\n",
            "Epoch 25/26\n",
            "24/24 [==============================] - 16s 642ms/step - loss: 5.7673 - accuracy: 0.0266\n",
            "Epoch 26/26\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 5.7457 - accuracy: 0.0253\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d24780f7370>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "57pzY3txXNb2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"That hath deprived me of your\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, max_sequence_len)\n",
        "print(f\"Next word prediction: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiafAcwVYidV",
        "outputId": "ab9ecbdd-617b-420f-9415-d86a9c018f59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: and\n"
          ]
        }
      ]
    }
  ]
}