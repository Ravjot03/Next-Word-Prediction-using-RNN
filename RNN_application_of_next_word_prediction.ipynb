{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wgBNBLxzDlLq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,SimpleRNN,Dense"
      ],
      "metadata": {
        "id": "fIUSBCwjGIyY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plays=pd.read_csv(\"/content/Shakespeare_data.csv\")\n",
        "plays.shape\n",
        "plays.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0vPl40DIBFx",
        "outputId": "cd157248-68db-4dd0-e746-48bc842c4277"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Dataline', 'Play', 'PlayerLinenumber', 'ActSceneLine', 'Player',\n",
              "       'PlayerLine'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_lines=plays['PlayerLine'].sample(n=100,random_state=42)\n",
        "data=\" \".join(samples_lines)"
      ],
      "metadata": {
        "id": "4KzXCuFqIWJs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "mWPotfP3KGQ6",
        "outputId": "82b5599c-f211-4130-f6bd-ed2e5a0545f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That hath deprived me of your grace and favour, Their bodies, even to loathing, for they so stunk, Men at some time are masters of their fates: Disgorges such a tempest forth, That monster, custom, who all sense doth eat, To this chair bind him. Villain, thou shalt find-- Dexterity so obeying appetite Hector, in view of Trojans and of Greeks, Who know the world, see heaven, but, feeling woe, I should my tears let fall upon your cheek, Let not that doctor e'er come near my house: Arise, and say how thou camest here. Have I not heard these islanders shout out and one thing more, that you be never so hardy to And say I am Revenge, sent from below To furnish me upon my longing journey. All his revenue. And thus the native hue of resolution Why, art thou mad, old fellow? porringer fell off her head, for kindling such a That you shall stifle in your own report Is not this suit of mine, that thou declare It is as easy to count atomies as to resolve the But let this same be presently perform'd, The offers we have sent you. Now to deliver her possession up O Jupiter! there's no comparison. That none shall have access unto Bianca Have done me shame: brave soldier, pardon me, Dearer than eye-sight, space, and liberty, Nay, but it is not so. Be not you spoke with, but by mighty suit: Help, help, ho! Go to, sir: tell me, do you know Madam Silvia? That is thy means to live. Do thou but think To Mantua, where I hear he makes abode, Thunder. Third Apparition: a Child crowned, with a tree in his hand What folly 'tis to hazard life for ill! By heaven, it shall not go! And wilt thou have me? Of space had pointed him sharp as my needle, That I did never, no, nor never can, They bore him barefaced on the bier, And be it moon, or sun, or what you please: Should he sit here? This act persuades me Ay, he does well enough if he be disposed, and so do And calls them brothers, friends and countrymen. And I will. Hear me, my liege: For I am arm'd so strong in honesty No, if I digg'd up thy forefathers' graves Touch not the boy, he is of royal blood. I am so far already in your gifts,-- I would thou grew'st unto the shores o' the haven, From forth the fatal loins of these two foes Be these the wretches that we play'd at dice for? He hath refused it in the open court: To seek out sorrow that dwells every where. perfect gallows. Stand fast, good Fate, to his That's it, I would have said the very same. Exit what we may be. God be at your table! The Lady Anne pass from her coronation? Strike a free march to Troy! with comfort go: hang'd first. A fair one are you--well you fit our ages Ay. The very doors and windows savour vilely. I will not harbour in this town to-night: By my fidelity, this is not well, Master Ford, this There, my lord: Whereat, with blade, with bloody blameful blade, Claribel. but blow them to their trial, the bubbles are out. What say ye, countrymen? will ye relent, As thou dost swallow up this good king's blood I will say nothing. death: her death itself, which could not be her That you might see your shadow. I have heard, To set thee here? Come our lovely lady nigh, And that you fly them as you swear them lordship, And buy men's voices to commend our deeds: On which I'll toss the flower-de-luce of France. Your grace, that fed my country with your corn, Writes that knows me to be in love, yet I am in love, but a Well, come, my Kate, we will unto your father's Rankly abused: but know, thou noble youth, All points of my command. Brentford: but that my admirable dexterity of wit, bass-viol, in a case of leather, the man, sir, How to lament the cause. I'll beg one boon, Four legs and two voices: a most delicate monster! could not have owed her a more rooted love. Proceed. SCENE VI. The same. A banqueting-room in Timon's house. Will kneel to him with thanks. And a demand who is't shall die, I'd say Oft have I heard of sanctuary men,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "word_index=tokenizer.word_index\n",
        "total_words=len(word_index)+1"
      ],
      "metadata": {
        "id": "vCnzvyDsJDDK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "token_list=tokenizer.texts_to_sequences([data])[0]\n",
        "for i in range(1,len(token_list) ):\n",
        "  n_gram_sequence=token_list[:i+1]\n",
        "  input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "NMk_qUhjL8F2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len=max([len(seq) for seq in input_sequences])\n",
        "input_sequences=pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre')"
      ],
      "metadata": {
        "id": "eK9HGgqsRTm7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y=to_categorical(y,num_classes=total_words)"
      ],
      "metadata": {
        "id": "eMFu1KTeS5Aw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(total_words,1000,input_length=max_sequence_len-1))\n",
        "model.add(SimpleRNN(200))\n",
        "model.add(Dense(total_words,activation='softmax'))"
      ],
      "metadata": {
        "id": "mZkNCvTbTpBA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOky7Dw9Ty36",
        "outputId": "027c52ed-9e14-4053-a8f9-b4f2527d26ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 751, 1000)         387000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 200)               240200    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 387)               77787     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 704987 (2.69 MB)\n",
            "Trainable params: 704987 (2.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is8aPI0uT6rc",
        "outputId": "96463259-49a3-4282-aee8-9395c5458684"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 14s 819ms/step - loss: 5.9450 - accuracy: 0.0120\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 9s 771ms/step - loss: 5.5471 - accuracy: 0.0706\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 5.1527 - accuracy: 0.1704\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 8s 709ms/step - loss: 4.7774 - accuracy: 0.2490\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 8s 669ms/step - loss: 4.3731 - accuracy: 0.3369\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 8s 591ms/step - loss: 3.9621 - accuracy: 0.4541\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 8s 695ms/step - loss: 3.5220 - accuracy: 0.5952\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 15s 1s/step - loss: 3.0715 - accuracy: 0.7417\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 9s 778ms/step - loss: 2.6285 - accuracy: 0.8402\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 2.1934 - accuracy: 0.9041\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 8s 702ms/step - loss: 1.7634 - accuracy: 0.9587\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 7s 576ms/step - loss: 1.3815 - accuracy: 0.9840\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 8s 602ms/step - loss: 1.0604 - accuracy: 0.9920\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 8s 700ms/step - loss: 0.7976 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 7s 567ms/step - loss: 0.5998 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 8s 688ms/step - loss: 0.4579 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.3549 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 8s 570ms/step - loss: 0.2806 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 8s 713ms/step - loss: 0.2286 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 7s 566ms/step - loss: 0.1903 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 8s 711ms/step - loss: 0.1621 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 8s 656ms/step - loss: 0.1402 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 7s 561ms/step - loss: 0.1232 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 8s 682ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 7s 570ms/step - loss: 0.0977 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 8s 709ms/step - loss: 0.0882 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 8s 689ms/step - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 7s 557ms/step - loss: 0.0734 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 8s 707ms/step - loss: 0.0674 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 7s 567ms/step - loss: 0.0622 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 8s 688ms/step - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 8s 696ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 7s 566ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 8s 697ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 7s 565ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 8s 645ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 8s 695ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 7s 560ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 8s 706ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 7s 554ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 8s 654ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 8s 696ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 7s 555ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 8s 703ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 7s 566ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 8s 699ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 7s 550ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 8s 694ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 7s 564ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 8s 703ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 7s 560ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 8s 700ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 8s 717ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 7s 568ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 8s 705ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 7s 565ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 8s 711ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 9s 734ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 8s 724ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 8s 684ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 7s 572ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 9s 725ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 8s 692ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 9s 728ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 8s 695ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 8s 568ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 8s 704ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 7s 563ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 8s 713ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 8s 698ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 7s 585ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 9s 723ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 7s 583ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 8s 692ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 7s 565ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 8s 698ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 7s 563ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 8s 643ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 8s 704ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 7s 573ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 8s 693ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 8s 634ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 8s 573ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 8s 709ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 7s 570ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 8s 700ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 8s 709ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 7s 567ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 8s 692ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 7s 565ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 8s 708ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 8s 692ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 7s 565ms/step - loss: 0.0059 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78348e795330>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "57pzY3txXNb2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"That hath deprived me of your\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, max_sequence_len)\n",
        "print(f\"Next word prediction: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiafAcwVYidV",
        "outputId": "441e9949-beab-451e-fa65-0ae053178f9c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: grace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"To furnish me upon my longing\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, max_sequence_len)\n",
        "print(f\"Next word prediction: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrgpRqk1YEwm",
        "outputId": "aa948f84-f3be-4394-e86c-bb37986394b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: journey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Dexterity so obeying appetite\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, max_sequence_len)\n",
        "print(f\"Next word prediction: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtzgHrhKYMqP",
        "outputId": "c55a67f3-5415-40fb-882b-5f37572bc8e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: hector\n"
          ]
        }
      ]
    }
  ]
}
